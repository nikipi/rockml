
factors = ['OperatingRevenueGrowRate',
       'NetProfitGrowRate', 'TVSTD20', 'TVSTD6', 'TVMA20', 'TVMA6', 'BLEV',
       'MLEV', 'CashToCurrentLiability', 'CurrentRatio', 'REC', 'DAREC',
       'GREC', 'DASREV', 'SFY12P', 'LCAP', 'ASSI', 'LFLO', 'TA2EV', 'PE', 'PB',
       'PS', 'SalesCostRatio', 'PCF', 'TotalProfitGrowRate', 'CTOP', 'MACD',
       'DEA', 'DIFF', 'RSI', 'PSY', 'BIAS10', 'ROE', 'ROA', 'ROA5', 'ROE5',
       'DEGM', 'GrossIncomeRatio', 'CurrentAssetsTRate', 'FixedAssetsTRate',
       'PLRC6', 'REVS5', 'REVS10', 'REVS20', 'HSIGMA', 'ChaikinOscillator',
       'ChaikinVolatility', 'Aroon', 'DDI', 'MTM', 'MTMMA', 'VOL10', 'VOL20',
       'VOL5', 'VOL60', 'DDNSR', 'Hurst']

# df = pd.read_csv(u'/Users/ypi/Desktop/combined_csv.csv', dtype={"ticker": np.str, "tradeDate": np.str, "next_month_end": np.str},index_col=0, encoding='GBK')
#
#
#
# df['year']= pd.to_numeric(df['tradeDate'].str[:4])
# print(df.info())
#
# class BoostModel:
#     def __init__(self,
#                  max_depth=3,
#                  subsample=0.95,
#                  num_round =2000,
#                  early_stopping_rounds=50):
#         self.params = {'mex_depth':max_depth,
#                        'eta':0.1, 'silent':1,
#                        'alpha':0.5,"lambda":0.5,
#                        'eval_metric':'auc','subsample':subsample,
#                        'objective':'binary:logistic'}
#         self.num_round = num_round
#         self.early_stopping_rounds = early_stopping_rounds
#
#     def fit(self, train_data, train_label, val_data, val_label):
#         dtrain = xgb.DMatrix(train_data, label=train_label)
#         deval = xgb.DMatrix(val_data, label=val_label)
#
#
#         boost_model = xgb.train(self.params, dtrain, num_boost_round=self.num_round,
#                                     evals=[(dtrain, 'train'), (deval, 'eval')],
#                                     early_stopping_rounds=self.early_stopping_rounds, verbose_eval=False)
#         print('get best eval auc : %s, in step %s' % (boost_model.best_score, boost_model.best_iteration))
#         self.boost_model = boost_model
#
#         return boost_model
#
#     def predict(self,test_data):
#         dtest = xgb.DMatrix(test_data)
#         predict_score = self.boost_model.predict(dtest, ntree_limit = self.boost_model.best_ntree_limit)
#         return predict_score
#
#
# def get_train_val_test_data(year, split_pct =0.9):
#     back_year = max(2007, year-6)
#     train_val_df = df[(df['year']>=back_year) & (df['year']<year)]
#     train_val_df = train_val_df.sample(frac=1).reset_index(drop=True)
#
#     train_df = train_val_df.iloc[0:int(len(train_val_df)*split_pct)]
#     val_df = train_val_df.iloc[int(len(train_val_df) * split_pct):]
#
#     test_df = df[df['year']==year]
#
#     return train_df, val_df,test_df
#
# def format_feature_label(origin_df, is_train = True):
#     if is_train:
#         origin_df = origin_df[origin_df['label']!=0]
#         origin_df['label'] = origin_df['label'].replace(-1,0)
#
#     feature = np.array(origin_df[factors])
#     label = np.array(origin_df['label'])
#
#     return feature, label
#
# def write_factor_to_csv(df,predict_socre,year):
#     df['factor_score'] = predict_socre
#     filtered_columns = ['ticker', 'tradeDate', 'label', 'factor_score']
#     df = df.reindex(columns=filtered_columns)
#     is_header = True
#     if year != 2011:
#         is_header = False
#
#     df.to_csv('/Users/ypi/Desktop/raw_data.csv', mode='a+', encoding='utf-8', header=is_header)
#
#
#
#
# def pipeline():
#     boost_model_list = []
#     for year in range(2011,2018):
#         print('training model for %s' %year)
#         train_df,val_df, test_df = get_train_val_test_data(year)
#         boost_model = BoostModel()
#         train_feature, train_label = format_feature_label(train_df)
#         val_feature, val_label = format_feature_label(val_df)
#
#         boost_model.fit(train_feature, train_label, val_feature, val_label)
#
#         test_feature, test_label = format_feature_label(test_df, False)
#         predict_score = boost_model.predict(test_feature)
#         write_factor_to_csv(test_df, predict_score, year)
#         boost_model_list.append(boost_model)
#     return boost_model_list
#
# boost_model_list = pipeline()
#
#
#
#
# from sklearn.metrics import roc_auc_score
# import matplotlib.pyplot as plt
#
# def get_test_auc_acc():
#     df = pd.read_csv('/Users/ypi/Desktop/raw_data.csv')
#     df= df[df['label']!=0]
#     df.loc[:,'predict'] = df.loc[:,'factor_score'].apply(
#            lambda x: 1 if x>0.5 else -1
#     )
#
#     acc_list = []
#     auc_list = []
#
#     for date, group in df.groupby('tradeDate'):
#            df_correct = group[group["label"]== group['predict']]
#            correct = len(df_correct) * 1.0 / len(group)
#            auc = roc_auc_score(np.array(group["label"]),
#                                np.array(group['factor_score']))
#            acc_list.append([date,correct])
#            auc_list.append([date,auc])
#
#     acc_list = sorted(acc_list, key= lambda x:x[0],reverse = False)
#     mean_acc = sum([item[1] for item in acc_list])/len(acc_list)
#
#     auc_list = sorted(auc_list, key= lambda x: x[0], reverse= False)
#     mean_auc = sum([item[1] for item in auc_list])/len(auc_list)
#     print(acc_list)
#     print(auc_list)
#
#     return acc_list, auc_list, round(mean_auc,2), round(mean_auc,2)
#
# from datetime import datetime
# def plot_accuracy_curve():
#        acc_list, auc_list, mean_acc, mean_auc = get_test_auc_acc()
#
#        plt.plot([datetime.strptime(str(item[0]), '%Y%m%d') for item in acc_list], [item[1] for item in acc_list], '-bo')
#        plt.plot([datetime.strptime(str(item[0]), '%Y%m%d') for item in auc_list], [item[1] for item in auc_list], '-ro')
#
#        plt.legend([u"acc curve: mean_acc:%s" % mean_acc, u"auc curve: mean auc:%s" % mean_auc], loc='upper left',
#                   handlelength=2, handletextpad=0.5, borderpad=0.1)
#        plt.ylim((0.3, 1))
#        plt.show()
#
#
# plot_accuracy_curve()
